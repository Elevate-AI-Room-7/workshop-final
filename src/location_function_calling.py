"""
Location Function Calling System using LangChain
Implements function calling to detect and request location information from users
"""

import json
from typing import Dict, Any, Optional, List
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, SystemMessage


@tool
def request_location_information(
    query_type: str, 
    context: str = "", 
    suggested_locations: List[str] = None
) -> Dict[str, Any]:
    """
    Request location information from user when location is missing or unclear.
    
    Args:
        query_type: Type of query needing location (weather, hotel, car, travel_plan)
        context: Additional context about the request
        suggested_locations: List of suggested locations based on context
        
    Returns:
        Dict with request message and suggestions
    """
    
    query_prompts = {
        "weather": {
            "message": "üèôÔ∏è **T√¥i c·∫ßn bi·∫øt ƒë·ªãa ƒëi·ªÉm ƒë·ªÉ ki·ªÉm tra th·ªùi ti·∫øt.**\n\nB·∫°n mu·ªën xem th·ªùi ti·∫øt ·ªü ƒë√¢u?",
            "examples": ["H√† N·ªôi", "ƒê√† N·∫µng", "H·ªì Ch√≠ Minh", "Nha Trang", "Hu·∫ø"]
        },
        "hotel": {
            "message": "üè® **T√¥i c·∫ßn bi·∫øt ƒë·ªãa ƒëi·ªÉm ƒë·ªÉ t√¨m kh√°ch s·∫°n.**\n\nB·∫°n mu·ªën ƒë·∫∑t kh√°ch s·∫°n ·ªü th√†nh ph·ªë n√†o?",
            "examples": ["H√† N·ªôi", "ƒê√† N·∫µng", "H·ªì Ch√≠ Minh", "H·ªôi An", "Sapa"]
        },
        "car": {
            "message": "üöó **T√¥i c·∫ßn bi·∫øt ƒëi·ªÉm ƒë√≥n v√† ƒëi·ªÉm ƒë·∫øn ƒë·ªÉ ƒë·∫∑t xe.**\n\nB·∫°n mu·ªën ƒëi t·ª´ ƒë√¢u ƒë·∫øn ƒë√¢u?",
            "examples": ["T·ª´ s√¢n bay N·ªôi B√†i ƒë·∫øn trung t√¢m H√† N·ªôi", "T·ª´ H√† N·ªôi ƒëi H·∫° Long"]
        },
        "travel_plan": {
            "message": "üß≥ **T√¥i c·∫ßn bi·∫øt ƒëi·ªÉm ƒë·∫øn ƒë·ªÉ l·∫≠p k·∫ø ho·∫°ch du l·ªãch.**\n\nB·∫°n mu·ªën du l·ªãch ·ªü ƒë√¢u?",
            "examples": ["Sapa", "ƒê√† L·∫°t", "Ph√∫ Qu·ªëc", "H·∫° Long", "H·ªôi An"]
        }
    }
    
    prompt_info = query_prompts.get(query_type, query_prompts["weather"])
    
    # Use suggested locations if provided, otherwise use default examples
    examples = suggested_locations if suggested_locations else prompt_info["examples"]
    
    response_message = f"{prompt_info['message']}\n\nüí° **G·ª£i √Ω:** {', '.join(examples)}"
    
    if context:
        response_message += f"\n\nüìù **Ng·ªØ c·∫£nh:** {context}"
    
    return {
        "needs_location": True,
        "response": response_message,
        "query_type": query_type,
        "suggested_locations": examples,
        "tool_used": "LOCATION_REQUEST"
    }


@tool 
def extract_location_from_text(
    text: str,
    conversation_history: str = "",
    prioritize_provinces: bool = True
) -> Dict[str, Any]:
    """
    Extract location information from text using comprehensive location database.
    
    Args:
        text: Text to extract location from
        conversation_history: Previous conversation context
        prioritize_provinces: Whether to prioritize provinces over cities
        
    Returns:
        Dict with extracted location information
    """
    
    # Comprehensive Vietnam location database
    provinces = [
        "ki√™n giang", "an giang", "c√† mau", "b·∫°c li√™u", "s√≥c trƒÉng", 
        "ƒë·ªìng th√°p", "ti·ªÅn giang", "b·∫øn tre", "vƒ©nh long", "tr√† vinh",
        "h√† giang", "cao b·∫±ng", "l√†o cai", "y√™n b√°i", "tuy√™n quang",
        "th√°i nguy√™n", "b·∫Øc k·∫°n", "lang s∆°n", "qu·∫£ng ninh", "h·∫£i ph√≤ng",
        "nam ƒë·ªãnh", "th√°i b√¨nh", "h∆∞ng y√™n", "h√† nam", "ninh b√¨nh",
        "thanh h√≥a", "ngh·ªá an", "h√† tƒ©nh", "qu·∫£ng b√¨nh", "qu·∫£ng tr√¨",
        "qu·∫£ng nam", "qu·∫£ng ng√£i", "b√¨nh ƒë·ªãnh", "ph√∫ y√™n", "kh√°nh h√≤a",
        "ninh thu·∫≠n", "b√¨nh thu·∫≠n", "kon tum", "gia lai", "ƒë·∫Øk l·∫Øk",
        "ƒë·∫Øk n√¥ng", "l√¢m ƒë·ªìng", "b√¨nh ph∆∞·ªõc", "t√¢y ninh", "b√¨nh d∆∞∆°ng",
        "ƒë·ªìng nai", "b√† r·ªãa v≈©ng t·∫ßu", "long an"
    ]
    
    cities = [
        "h√† n·ªôi", "h·ªì ch√≠ minh", "ƒë√† n·∫µng", "nha trang", "hu·∫ø", "h·ªôi an", 
        "sapa", "ƒë√† l·∫°t", "ph√∫ qu·ªëc", "c·∫ßn th∆°", "v≈©ng t·∫ßu", "phan thi·∫øt",
        "h·∫° long", "ninh b√¨nh", "m√π cang ch·∫£i", "tam c·ªëc", "b√°i ƒë√≠nh",
        "sa pa", "m≈©i n√©", "c√¥n ƒë·∫£o", "c√°t b√†", "h√≤a b√¨nh"
    ]
    
    all_locations = provinces + cities
    
    # Normalize text for searching
    text_lower = text.lower().strip()
    history_lower = conversation_history.lower().strip()
    
    found_locations = []
    
    # Search in main text first (highest priority)
    for location in all_locations:
        if location in text_lower:
            priority = "province" if location in provinces else "city"
            found_locations.append({
                "location": location.title(),
                "source": "text",
                "priority": priority,
                "confidence": 0.9
            })
    
    # Search in conversation history (lower priority)
    if not found_locations and history_lower:
        for location in all_locations:
            if location in history_lower:
                priority = "province" if location in provinces else "city" 
                found_locations.append({
                    "location": location.title(),
                    "source": "history",
                    "priority": priority,
                    "confidence": 0.7
                })
    
    if found_locations:
        # Sort by confidence and priority
        if prioritize_provinces:
            found_locations.sort(key=lambda x: (
                x["confidence"], 
                x["priority"] == "province", 
                x["source"] == "text"
            ), reverse=True)
        else:
            found_locations.sort(key=lambda x: (
                x["confidence"],
                x["source"] == "text"
            ), reverse=True)
        
        best_match = found_locations[0]
        
        return {
            "location_found": True,
            "location": best_match["location"],
            "source": best_match["source"],
            "confidence": best_match["confidence"],
            "all_candidates": found_locations,
            "tool_used": "LOCATION_EXTRACTION"
        }
    
    return {
        "location_found": False,
        "location": None,
        "source": None,
        "confidence": 0.0,
        "all_candidates": [],
        "tool_used": "LOCATION_EXTRACTION"
    }


class LocationFunctionCaller:
    """
    LangChain-based function calling system for location detection
    """
    
    def __init__(self, openai_api_key: str = None, model: str = "gpt-3.5-turbo"):
        """Initialize the function calling system"""
        
        self.use_agent = False
        self.agent_executor = None
        
        # Only initialize agent if API key is available
        if openai_api_key:
            try:
                self.llm = ChatOpenAI(
                    model=model,
                    api_key=openai_api_key,
                    temperature=0.1  # Low temperature for consistent results
                )
                self.use_agent = True
            except Exception as e:
                print(f"‚ö†Ô∏è Could not initialize OpenAI agent: {str(e)}")
                self.use_agent = False
        
        # Define available tools
        self.tools = [
            request_location_information,
            extract_location_from_text
        ]
        
        # Initialize agent components only if using agent
        if self.use_agent:
            # Create the function calling prompt
            self.prompt = ChatPromptTemplate.from_messages([
                SystemMessage(content="""B·∫°n l√† tr·ª£ l√Ω du l·ªãch th√¥ng minh chuy√™n x·ª≠ l√Ω th√¥ng tin ƒë·ªãa ƒëi·ªÉm.

Nhi·ªám v·ª• c·ªßa b·∫°n:
1. Ph√¢n t√≠ch y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng ƒë·ªÉ x√°c ƒë·ªãnh xem c√≥ c·∫ßn th√¥ng tin ƒë·ªãa ƒëi·ªÉm kh√¥ng
2. Tr√≠ch xu·∫•t ƒë·ªãa ƒëi·ªÉm t·ª´ vƒÉn b·∫£n n·∫øu c√≥
3. Y√™u c·∫ßu ng∆∞·ªùi d√πng cung c·∫•p ƒë·ªãa ƒëi·ªÉm n·∫øu thi·∫øu v√† c·∫ßn thi·∫øt

Quy t·∫Øc x·ª≠ l√Ω:
- Lu√¥n ∆∞u ti√™n ƒë·ªãa ƒëi·ªÉm ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p tr·ª±c ti·∫øp trong c√¢u h·ªèi
- N·∫øu kh√¥ng c√≥ ƒë·ªãa ƒëi·ªÉm trong c√¢u h·ªèi, ki·ªÉm tra l·ªãch s·ª≠ h·ªôi tho·∫°i
- N·∫øu v·∫´n kh√¥ng c√≥, y√™u c·∫ßu ng∆∞·ªùi d√πng cung c·∫•p
- KH√îNG BAO GI·ªú t·ª± ƒë·ªông ch·ªçn ƒë·ªãa ƒëi·ªÉm m·∫∑c ƒë·ªãnh

Lo·∫°i y√™u c·∫ßu c·∫ßn ƒë·ªãa ƒëi·ªÉm:
- weather: Ki·ªÉm tra th·ªùi ti·∫øt
- hotel: ƒê·∫∑t kh√°ch s·∫°n  
- car: ƒê·∫∑t xe di chuy·ªÉn
- travel_plan: L·∫≠p k·∫ø ho·∫°ch du l·ªãch"""),
                
                HumanMessage(content="{input}"),
                MessagesPlaceholder(variable_name="agent_scratchpad")
            ])
            
            # Create the agent
            self.agent = create_openai_functions_agent(
                llm=self.llm,
                tools=self.tools,
                prompt=self.prompt
            )
            
            # Create agent executor
            self.agent_executor = AgentExecutor(
                agent=self.agent,
                tools=self.tools,
                verbose=False,
                handle_parsing_errors=True,
                max_iterations=3
            )
    
    def detect_and_handle_location(
        self, 
        user_query: str,
        query_type: str,
        conversation_history: str = "",
        context: str = ""
    ) -> Dict[str, Any]:
        """
        Main method to detect location or request it from user
        
        Args:
            user_query: User's query text
            query_type: Type of query (weather, hotel, car, travel_plan)
            conversation_history: Previous conversation context
            context: Additional context
            
        Returns:
            Dict with location information or request message
        """
        
        # Prepare input for the agent
        full_context = f"Conversation History: {conversation_history}\nContext: {context}" if conversation_history or context else ""
        
        agent_input = f"""
Ph√¢n t√≠ch y√™u c·∫ßu sau:

C√¢u h·ªèi: "{user_query}"
Lo·∫°i y√™u c·∫ßu: {query_type}
Ng·ªØ c·∫£nh: {full_context}

H√£y x·ª≠ l√Ω theo quy tr√¨nh:
1. Tr√≠ch xu·∫•t ƒë·ªãa ƒëi·ªÉm t·ª´ c√¢u h·ªèi b·∫±ng extract_location_from_text
2. N·∫øu kh√¥ng t√¨m th·∫•y ƒë·ªãa ƒëi·ªÉm, s·ª≠ d·ª•ng request_location_information ƒë·ªÉ y√™u c·∫ßu ng∆∞·ªùi d√πng cung c·∫•p
"""
        
        # If no agent available, use direct tool calls
        if not self.use_agent or self.agent_executor is None:
            return self._fallback_location_detection(user_query, query_type, conversation_history)
        
        try:
            # Execute the agent
            result = self.agent_executor.invoke({
                "input": agent_input
            })
            
            # Parse the result
            output = result.get("output", "")
            
            # Try to extract structured information from the output
            return self._parse_agent_output(output, user_query, query_type)
            
        except Exception as e:
            # Fallback to direct tool usage
            return self._fallback_location_detection(user_query, query_type, conversation_history)
    
    def _parse_agent_output(self, output: str, user_query: str, query_type: str) -> Dict[str, Any]:
        """Parse agent output to extract structured location information"""
        
        # Try to extract location information from output
        if "location_found" in output.lower() and "true" in output.lower():
            # Location was found
            return {
                "success": True,
                "location_found": True,
                "response": output,
                "tool_used": "FUNCTION_CALLING_EXTRACTION"
            }
        elif "needs_location" in output.lower() and "true" in output.lower():
            # Location request needed
            return {
                "success": True,
                "location_found": False,
                "needs_location": True,
                "response": output,
                "tool_used": "FUNCTION_CALLING_REQUEST"
            }
        else:
            # Parse the text output
            return {
                "success": True,
                "location_found": False,
                "response": output,
                "tool_used": "FUNCTION_CALLING_RESPONSE"
            }
    
    def _fallback_location_detection(
        self, 
        user_query: str, 
        query_type: str, 
        conversation_history: str = ""
    ) -> Dict[str, Any]:
        """Fallback method using direct tool calls"""
        
        try:
            # Try to extract location directly
            extraction_result = extract_location_from_text.invoke({
                "text": user_query,
                "conversation_history": conversation_history
            })
            
            if extraction_result["location_found"]:
                return {
                    "success": True,
                    "location_found": True,
                    "location": extraction_result["location"],
                    "confidence": extraction_result["confidence"],
                    "response": f"ƒê√£ x√°c ƒë·ªãnh ƒë·ªãa ƒëi·ªÉm: {extraction_result['location']}",
                    "tool_used": "FALLBACK_EXTRACTION"
                }
            else:
                # Request location from user
                request_result = request_location_information.invoke({
                    "query_type": query_type,
                    "context": user_query
                })
                
                return {
                    "success": True,
                    "location_found": False,
                    "needs_location": True,
                    "response": request_result["response"],
                    "suggested_locations": request_result["suggested_locations"],
                    "tool_used": "FALLBACK_REQUEST"
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "response": "C√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω th√¥ng tin ƒë·ªãa ƒëi·ªÉm.",
                "tool_used": "FALLBACK_ERROR"
            }